{"text": "[Paper ID: 3]\n\nGenerative models for continuous domains have enabled numerous applications in images (Rombach et al., 2022; Saharia et al., 2022; Esser et al., 2024), videos (Ho et al., 2022a; Blattmann et al., 2023; OpenAI, 2024), and audio (Chen et al., 2020; Kong et al., 2020; Liu et al., 2023), yet achieving high-fidelity outputs, efficient inference, and stable training remains a core challenge — a trilemma that continues to motivate research in this domain. Diffusion models (Sohl-Dickstein et al., 2015; Ho et al., 2020; Song et al., 2020b), one of the leading techniques, require many inference steps for high-quality results, while step-reduction methods, such as diffusion distillation (Yin et al., 2024; Sauer et al., 2025; Zhou et al., 2024; Luo et al., 2024a) and Consistency Models (Song et al., 2023; Geng et al., 2024; Lu & Song, 2024; Kim et al., 2023), often risk training collapse without careful tuning and regularization (such as pre-generating data-noise pair and early stopping).\n\nTo address the aforementioned trilemma, we introduce Inductive Moment Matching (IMM), a stable, single-stage training procedure that learns generative models from scratch for single- or multi-step inference. IMM operates on the time-dependent marginal distributions of stochastic interpolants (Albergo et al., 2023) — continuous-time stochastic processes that connect two arbitrary probability density functions (data at t=0 and prior at t=1). By learning a (stochastic or deterministic) mapping from any marginal at time t=1 to any marginal at time s<t, it can naturally support one- or multi-step generation (Figure 2).\n\nIMM models can be trained efficiently from mathematical induction. For time s<r<t, we form two distributions at s by running a one-step IMM from samples at r and t. We then minimize their divergence, enforcing that the distributions at s are close to the distributions at r. This construction by induction guarantees convergence to the data distribution. To help with training stability, we model IMM based on certain stochastic interpolants and optimize the objective with stable sample-based divergence estimators such as moment matching (Gretton et al., 2012). Notably, we prove that Consistency Models (CMs) are a single-particle, first-moment matching special case of IMM, which partially explains the training instability of CMs.\n\nOn ImageNet-256x256, IMM surpasses diffusion models and achieves 1.99 FID with only 8 inference steps using standard transformer architectures. On CIFAR-10, IMM similarly achieves state-of-the-art of 1.98 FID with 2-step generation for a model trained from scratch."}
