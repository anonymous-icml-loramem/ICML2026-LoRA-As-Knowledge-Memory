You are an expert academic assistant tasked with creating a high-quality question-answering dataset from a research paper's introduction. Your goal is to generate 30 question-and-answer pairs based exclusively on the provided text.

Instructions and Rules:
Source Grounding: All questions and answers MUST be derived solely from the provided introduction text. Do not use any external knowledge or make assumptions beyond what is written.

Question Hierarchy: You must create questions across three distinct levels of understanding, as defined below.

Quantity: Generate exactly 30 pairs in total: 10 for Level 1, 10 for Level 2, and 10 for Level 3.

Output Format: The output must be a single, valid JSON array of objects. Do not include any explanatory text, comments, or markdown formatting before or after the JSON code block.

Question Level Definitions:
Level 1: Key Information Recall (10 Questions)

Objective: To test the recall of specific, explicitly stated facts, proper nouns, terminology, and figures from the text.

Question Type: "What is...?", "What are the names of...?", "Which X was mentioned...?"

Level 2: Contextual Comprehension (10 Questions)

Objective: To test the understanding of relationships between concepts, such as cause-and-effect, problem-solution, comparisons, and the function of a component.

Question Type: "Why does...?", "What is the effect of A on B?", "How does X work?", "What is the difference between A and B?"

Level 3: Logical Structure Inference (10 Questions)

Objective: To test the understanding of the overall logical flow of the text, including identifying the core problem, the research gap, the proposed solution, and the main contribution.

Question Type: "What is the core problem the authors aim to solve?", "What research gap does this paper intend to fill?", "What is the main advantage of the proposed method?", "Summarize the key contribution of this work in relation to prior limitations."

Desired JSON Output Format:
The final output MUST be a JSON array containing 30 objects. Each object must have three keys: level (integer: 1, 2, or 3), question (string), and answer (string).

Example:

[
  {
    "level": 1,
    "question": "What is the full name of the algorithm the authors integrate their estimator into?",
    "answer": "The authors integrated their estimator into the Generalized Successive Elimination algorithm."
  },
  {
    "level": 2,
    "question": "According to the text, what is the inverse relationship between response time and preference strength?",
    "answer": "The text states that users who strongly prefer to skip a product tend to do so quickly, while longer response times can indicate weaker preferences."
  },
  {
    "level": 3,
    "question": "What is the core reason complex psychological models are impractical for real-time systems, and how does this paper's proposal address it?",
    "answer": "They are impractical because they rely on computationally intensive methods like hierarchical Bayesian inference and MLE. This paper addresses it by proposing a computationally efficient method that frames utility estimation as a linear regression problem."
  }
]

Introduction Text to Analyze:
Title: Statistical Test for Feature Selection Pipelines by Selective Inference

In practical data-driven decision-making tasks, integrating various types of data analysis steps is crucial for addressing diverse challenges. For instance, in genetic research aimed at identifying genes linked to a specific disease, the process often begins with preprocessing tasks such as filling in missing values and detecting outliers. This is followed by screening for potentially related genes using simple descriptive statistics and then applying more complex machine learning-based feature selection algorithms. Such a systematic sequence of steps designed to analyze data and derive useful insights is known as a data analysis pipeline, which plays a key role in ensuring the reproducibility and reliability of data-driven decision-making.

In this study, as an example of data analysis pipelines, we consider a class of feature selection pipelines that integrates various missing-value imputations (MVI) algorithms, outlier detection (OD) algorithms, and feature selection (FS) algorithms. Figure 1 shows examples of two such pipelines. The pipeline on the left starts with a mean value imputation algorithm, followed by L1 regression based OD algorithm, proceeds with marginal screening to refine feature candidates, and concludes by using two FS algorithms—stepwise feature selection and Lasso—selecting their union as the final features. The pipeline on the right initiates with regression imputation, continues with marginal screening to narrow down feature candidates, uses Cook’s distance for OD, and applies both stepwise FS and Lasso, ultimately choosing the intersection of their results as the final features.

When a data-driven approach is used for high-stakes decision-making tasks such as medical diagnosis, it is crucial to quantify the reliability of the final results by considering all steps in the pipeline. The goal of this study is to develop a statistical test for a specific class of feature selection pipelines, allowing the statistical significance of features obtained through the pipeline to be properly quantified in the form of p-values. The first technical challenge in achieving this is the need to appropriately account for the complex interrelations between pipeline components to determine the overall statistical significance. The second challenge is to develop a universal framework capable of performing statistical tests on arbitrary pipelines (within a given class) rather than creating individual tests for each pipeline.

To address these challenges, we introduce the concept of selective inference (SI) (Taylor and Tibshirani, 2015; Fithian et al., 2015; Lee and Taylor, 2014), a novel statistical inference approach that has gained significant attention over the past decade. The core idea of SI is to characterize the process of selecting hypotheses from the data and calculate the corresponding p-values using the sampling distribution, conditional on this selection process. We propose an approach based on SI that provides valid p-values for any feature selection pipeline configuration within the aforementioned class. We also introduce a modular implementation framework that supports SI for any pipeline configuration within this class without requiring additional implementation efforts1. Specifically, with our framework, the statistical significance of features from any pipeline in this class can be quantified as valid p-values when used in a linear model, with no extra implementation required beyond specifying the pipeline.

We note that our long-term goal beyond this current study is to ensure the reproducibility of data-driven decision-making by accounting for the entire pipeline from raw data to the final results, with the current study on a class of feature selection pipelines serving as a proof of concept for that goal.

Now, generate the 30 Q&A pairs in the specified JSON format based on the text provided above.